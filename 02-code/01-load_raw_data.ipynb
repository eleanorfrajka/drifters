{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c548561e-bb83-48e3-9434-b14c17009d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import os\n",
    "import glob\n",
    "#import re\n",
    "#import sys\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from io import StringIO\n",
    "#from bs4 import BeautifulSoup\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e32bc8fd-633a-4534-807f-e57c7a6356e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Local import \n",
    "# > Make sure SIO_wrap dir is on the same path as this script.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from SIO_wrap import dir_tree, fnames\n",
    "\n",
    "from setdir import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d2a7402-5048-4802-a3d3-2692061c5169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_one_drifter(PID, base_url, username, password, \n",
    "                     download_start_date): \n",
    "    \n",
    "    from SIO_wrap import fnames\n",
    "    \n",
    "    tstr = f'start_date={download_start_date}'\n",
    "    pidstr = '&platform_id='\n",
    "\n",
    "    full_url = base_url+tstr+pidstr+PID\n",
    "\n",
    "    # Request file\n",
    "    resp = requests.get(full_url, auth=(username, password))\n",
    "    #    print(resp.status_code)\n",
    "    # Print the response code (200 is good. If you get something else, may be\n",
    "    # a password problem)\n",
    "\n",
    "    # To print content: resp.content\n",
    "    aa = resp.content.decode(\"utf-8\")\n",
    "    data_df = pd.read_csv(StringIO(aa))\n",
    "    \n",
    "    # Clean up column names\n",
    "    tmp = data_df.columns.str.strip()\n",
    "    tmp = tmp.str.replace(\" \", \"\", regex=True)\n",
    "    tmp = tmp.str.replace(\"-\", \"_\", regex=True)\n",
    "    tmp = tmp.str.replace(\"(\", \"_\", regex=True)\n",
    "    tmp = tmp.str.replace(')', '', regex=True)\n",
    "    data_df.columns = tmp\n",
    "    \n",
    "    # Remove the </br> column (IF IT EXISTS)\n",
    "    if '</br>' in data_df.columns:\n",
    "        data_df = data_df.drop(columns='</br>')\n",
    "        # data_df.dtypes\n",
    "    \n",
    "    # Convert the time column to a timestamp\n",
    "    time_colname = 'Timestamp_UTC'\n",
    "    data_df[time_colname] = pd.to_datetime(data_df[time_colname],\n",
    "                                       format=timcol_strftime) \n",
    "    \n",
    "    # Prep to convert xarray\n",
    "    data_df2 = data_df\n",
    "    data_df2[\"time\"] = data_df2[\"Timestamp_UTC\"].values\n",
    "    data_df2 = data_df2.set_index(\"time\")\n",
    "    data_df2 = data_df2.drop(columns='Timestamp_UTC')\n",
    "    # Convert to xarray\n",
    "    ds = data_df2.to_xarray()\n",
    "\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f1edef6-e0ca-4ff0-aa45-688449d8f554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Default download start date: 2019-12-04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################-----------   USER EDITS    ------------###################\n",
    "\n",
    "# Path where data are saved. Can be changed in file SIO_wrap/dir_tree.py\n",
    "data_dir = dir_tree.dir_out\n",
    "\n",
    "# Download start date must have format yyyy-mm-dd. Default is set to the\n",
    "# beginning of the TERIFIC project, i.e 2019-12-04.\n",
    "download_start_date = \"2019-12-04\"\n",
    "print(\"\\nDefault download start date: %s\\n\" % download_start_date)\n",
    "\n",
    "\n",
    "# SIO username and password\n",
    "username = \"uk-noc\"\n",
    "password = \"noc-drifter\"\n",
    "\n",
    "# URL for data\n",
    "base_url = \"https://gdp.ucsd.edu/cgi-bin/projects/uk-noc/drifter.py?\" \n",
    "\n",
    "# Options\n",
    "\n",
    "#full_url = base_url+tstr+pidstr\n",
    "#download_url = (\"https://gdp.ucsd.edu/cgi-bin/projects/uk-noc/\"\n",
    "#                \"drifter.py?start_date=\") \n",
    "\n",
    "\n",
    "# String formatting for time for:\n",
    "#   - the download url, \n",
    "#   - appending to the filename\n",
    "# \t- the data time column, respectively.\n",
    "url_strftime = '%Y-%m-%d'\n",
    "tstamp_strftime = '%Y%m%d'\n",
    "timcol_strftime = '%Y-%m-%d %H:%M:%S'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2cde915-36ee-4654-abec-ca3a8a469c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of Platform IDs\n",
    "PID = pd.read_csv(cat_proc_path('PID_list.txt'), header='infer', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7b2362d-429d-432c-b931-0c0ec449f029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. pid(300234066513050) - Ended:20220101, New end:20220101\n",
      "2. pid(300234068349690) - Ended:20220111, New end:20220117\n",
      "3. pid(300234068346620) - Ended:20220111, New end:20220117\n",
      "4. pid(300234068343550) - Ended:20220111, New end:20220117\n",
      "5. pid(300234068342020) - Ended:20220111, New end:20220117\n",
      "6. pid(300234068349700) - Ended:20220111, New end:20220117\n",
      "7. pid(300234068345610) - Ended:20220111, New end:20220117\n",
      "8. pid(300234068243230) - Ended:20220111, New end:20220117\n",
      "9. pid(300234068345630) - Ended:20220111, New end:20220117\n",
      "10. pid(300234068348190) - Ended:20220111, New end:20220117\n",
      "11. pid(300234066416930) - Ended:20220111, New end:20220117\n",
      "12. pid(300234068244270) - Ended:20220111, New end:20220117\n",
      "13. pid(300234068348210) - Ended:20220111, New end:20220117\n",
      "14. pid(300234068343610) - Ended:20220111, New end:20220117\n",
      "15. pid(300234068348220) - Ended:20220111, New end:20220117\n",
      "16. pid(300234068346690) - Ended:20220111, New end:20220117\n",
      "17. pid(300234068347720) - Ended:20220111, New end:20220117\n",
      "18. pid(300234068343630) - Ended:20220111, New end:20220117\n",
      "19. pid(300234068346190) - Ended:20220111, New end:20220117\n",
      "20. pid(300234068346200) - Ended:20220111, New end:20220117\n",
      "21. pid(300234068345690) - Ended:20220111, New end:20220117\n",
      "22. pid(300234068347740) - Ended:20220111, New end:20220117\n",
      "23. pid(300234068242270) - Ended:20220111, New end:20220117\n",
      "24. pid(300234068343650) - Ended:20220111, New end:20220117\n",
      "25. pid(300234068346740) - Ended:20220111, New end:20220113\n",
      "26. pid(300234068349820) - Ended:20220111, New end:20220117\n",
      "27. pid(300234068342660) - Ended:20220111, New end:20220117\n",
      "28. pid(300234068345220) - Ended:20220111, New end:20220117\n",
      "29. pid(300234068342150) - Ended:20220111, New end:20220117\n",
      "30. pid(300234068343690) - Ended:20220111, New end:20220117\n",
      "31. pid(300234068346250) - Ended:20220111, New end:20220117\n",
      "32. pid(300234068343190) - Ended:20220111, New end:20220117\n",
      "33. pid(300234068343700) - Ended:20220111, New end:20220117\n",
      "34. pid(300234068345240) - Ended:20220111, New end:20220117\n",
      "35. pid(300234068346270) - Ended:20220111, New end:20220117\n",
      "36. pid(300234068342690) - Ended:20220111, New end:20220117\n",
      "37. pid(300234068347820) - Ended:20220111, New end:20220117\n",
      "38. pid(300234068343730) - Ended:20220111, New end:20220117\n",
      "39. pid(300234068342720) - Ended:20220111, New end:20220117\n",
      "40. pid(300234068345290) - Ended:20220111, New end:20220117\n",
      "41. pid(300234068342220) - Ended:20220111, New end:20220117\n",
      "42. pid(300234068345300) - Ended:20220111, New end:20220117\n",
      "43. pid(300234066519000) - Ended:20220111, New end:20220117\n",
      "44. pid(300234068342750) - Ended:20220111, New end:20220117\n",
      "45. pid(300234066519010) - Ended:20220111, New end:20220117\n",
      "46. pid(300234068343270) - Ended:20220111, New end:20220117\n",
      "47. pid(300234068345830) - Ended:20220111, New end:20220117\n",
      "48. pid(300234068343280) - Ended:20220111, New end:20220117\n",
      "49. pid(300234068342270) - Ended:20220111, New end:20220117\n",
      "No more files to update\n"
     ]
    }
   ],
   "source": [
    "# Check which drifter files need to be updated\n",
    "# Save the list in PID_to_update\n",
    "PID_to_update = []\n",
    "counter = 0\n",
    "for i in range(len(PID)):\n",
    "    \n",
    "    # Get a single platform ID from the full list\n",
    "    pid1 = (PID[\"PID\"].values)[i].astype('str')\n",
    "    PID1 = (PID[\"PID\"].values)[i]\n",
    "\n",
    "    # Extract a list with the names of existing raw data files.\n",
    "    fname = 'pid'+str(PID1)+'_*'\n",
    "    existing_files = glob.glob(cat_raw_path(fname))\n",
    "    # Sort them alphabetically so the last element of the list is the \n",
    "    # latest date\n",
    "    existing_files = sorted(existing_files)\n",
    "    \n",
    "    if len(existing_files) > 0:\n",
    "        \n",
    "        # Extract the end date from the filename\n",
    "        end_date = (existing_files[-1])[-11:-3] # What order to these come in?\n",
    "        t1 = datetime.datetime.strptime(end_date, '%Y%m%d')  \n",
    "\n",
    "        # Download only the most recent drifter data \n",
    "        # (since the previous end date)\n",
    "        download_update = t1.strftime('%Y-%m-%d')\n",
    "        ds_update = load_one_drifter(pid1, base_url, username, password,\n",
    "                                     download_update)\n",
    "\n",
    "        # If there were at least 24 data points since the \n",
    "        # previous end date, then append the PID to the update list\n",
    "        if len(ds_update[\"time\"]) > 24:\n",
    "            counter += 1\n",
    "            maxtime = ds_update.time.max().values\n",
    "            new_end_date = pd.to_datetime(maxtime).strftime('%Y%m%d')\n",
    "\n",
    "            PID_to_update.append(PID1)\n",
    "            print(str(counter)+'. pid('+pid1+') - Ended:'+end_date\n",
    "                  +', New end:'+new_end_date)\n",
    "        \n",
    "    else:\n",
    "        counter += 1\n",
    "        print(str(counter)+'. pid('+pid1\n",
    "              +') - No previous raw data files.\\n')\n",
    "        PID_to_update.append(PID1)\n",
    "\n",
    "if counter==0:\n",
    "    print('All drifter files are up-to-date')\n",
    "    \n",
    "print('No more files to update')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "098c0215-012a-4bcd-aed8-4739a88d196d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ../01-data/01-raw/pid300234066513050_20220101.nc already exists!\n",
      "2. ../01-data/01-raw/pid300234068349690_20220117.nc\n",
      "3. ../01-data/01-raw/pid300234068346620_20220117.nc\n",
      "4. ../01-data/01-raw/pid300234068343550_20220117.nc\n",
      "5. ../01-data/01-raw/pid300234068342020_20220117.nc\n",
      "6. ../01-data/01-raw/pid300234068349700_20220117.nc\n",
      "7. ../01-data/01-raw/pid300234068345610_20220117.nc\n",
      "8. ../01-data/01-raw/pid300234068243230_20220117.nc\n",
      "9. ../01-data/01-raw/pid300234068345630_20220117.nc\n",
      "10. ../01-data/01-raw/pid300234068348190_20220117.nc\n",
      "11. ../01-data/01-raw/pid300234066416930_20220117.nc\n",
      "12. ../01-data/01-raw/pid300234068244270_20220117.nc\n",
      "13. ../01-data/01-raw/pid300234068348210_20220117.nc\n",
      "14. ../01-data/01-raw/pid300234068343610_20220117.nc\n",
      "15. ../01-data/01-raw/pid300234068348220_20220117.nc\n",
      "16. ../01-data/01-raw/pid300234068346690_20220117.nc\n",
      "17. ../01-data/01-raw/pid300234068347720_20220117.nc\n",
      "18. ../01-data/01-raw/pid300234068343630_20220117.nc\n",
      "19. ../01-data/01-raw/pid300234068346190_20220117.nc\n",
      "20. ../01-data/01-raw/pid300234068346200_20220117.nc\n",
      "21. ../01-data/01-raw/pid300234068345690_20220117.nc\n",
      "22. ../01-data/01-raw/pid300234068347740_20220117.nc\n",
      "23. ../01-data/01-raw/pid300234068242270_20220117.nc\n",
      "24. ../01-data/01-raw/pid300234068343650_20220117.nc\n",
      "25. ../01-data/01-raw/pid300234068346740_20220113.nc\n",
      "26. ../01-data/01-raw/pid300234068349820_20220117.nc\n",
      "27. ../01-data/01-raw/pid300234068342660_20220117.nc\n",
      "28. ../01-data/01-raw/pid300234068345220_20220117.nc\n",
      "29. ../01-data/01-raw/pid300234068342150_20220117.nc\n",
      "30. ../01-data/01-raw/pid300234068343690_20220117.nc\n",
      "31. ../01-data/01-raw/pid300234068346250_20220117.nc\n",
      "32. ../01-data/01-raw/pid300234068343190_20220117.nc\n",
      "33. ../01-data/01-raw/pid300234068343700_20220117.nc\n",
      "34. ../01-data/01-raw/pid300234068345240_20220117.nc\n",
      "35. ../01-data/01-raw/pid300234068346270_20220117.nc\n",
      "36. ../01-data/01-raw/pid300234068342690_20220117.nc\n",
      "37. ../01-data/01-raw/pid300234068347820_20220117.nc\n",
      "38. ../01-data/01-raw/pid300234068343730_20220117.nc\n",
      "39. ../01-data/01-raw/pid300234068342720_20220117.nc\n",
      "40. ../01-data/01-raw/pid300234068345290_20220117.nc\n",
      "41. ../01-data/01-raw/pid300234068342220_20220117.nc\n",
      "42. ../01-data/01-raw/pid300234068345300_20220117.nc\n",
      "43. ../01-data/01-raw/pid300234066519000_20220117.nc\n",
      "44. ../01-data/01-raw/pid300234068342750_20220117.nc\n",
      "45. ../01-data/01-raw/pid300234066519010_20220117.nc\n",
      "46. ../01-data/01-raw/pid300234068343270_20220117.nc\n",
      "47. ../01-data/01-raw/pid300234068345830_20220117.nc\n",
      "48. ../01-data/01-raw/pid300234068343280_20220117.nc\n",
      "49. ../01-data/01-raw/pid300234068342270_20220117.nc\n"
     ]
    }
   ],
   "source": [
    "# Loop through the list of Platform IDs of drifters that need to be updated\n",
    "# \n",
    "counter = 0\n",
    "for i in range(len(PID_to_update)):\n",
    "    counter += 1\n",
    "\n",
    "\n",
    "    \n",
    "    PID1 = PID_to_update[i]\n",
    "    pid1 = PID1.astype('str')\n",
    "    \n",
    "    # Load data into an xarray\n",
    "    ds = load_one_drifter(pid1, base_url, username, password,\n",
    "                               download_start_date)\n",
    "    \n",
    "    \n",
    "    # Get values for attributes\n",
    "    dstr = datetime.datetime.today()\n",
    "    dstr = dstr.replace(hour=0, minute=0, second=0, \n",
    "                        microsecond=0).strftime('%Y-%m-%d')\n",
    "\n",
    "    maxtime = ds.time.max().values\n",
    "    maxtimestr = pd.to_datetime(maxtime).strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "\n",
    "    project_name = 'TERIFIC'\n",
    "    operator_name = \"EFW\"\n",
    "    institution_name = 'National Oceanography Centre, UK'\n",
    "\n",
    "\n",
    "    # Create a dictionary of attributes\n",
    "    attr_dict = {\"Platform_ID\": PID1,\n",
    "                 \"End Time\": maxtimestr,\n",
    "                 \"Project\": project_name,\n",
    "                 \"Originator\": operator_name,\n",
    "                 \"Institution\": institution_name,\n",
    "                 \"Date created\": dstr,\n",
    "                }\n",
    "\n",
    "\n",
    "    ds = ds.assign_attrs(attr_dict)\n",
    "\n",
    "    ds = ds.drop('Platform_ID')\n",
    "    \n",
    "    # Sort by time ascending\n",
    "    ds = ds.sortby('time', ascending=True)\n",
    "\n",
    "\n",
    "\n",
    "    # Save file to raw - only if it doesn't already exist\n",
    "    enddate = pd.to_datetime(maxtime).strftime('%Y%m%d')\n",
    "    fname = 'pid'+str(PID1)+'_'+enddate+'.nc'\n",
    "    \n",
    "    outfile_with_path = cat_raw_path(fname)\n",
    "    if not os.path.isfile(outfile_with_path):\n",
    "        print(str(counter)+'. '+outfile_with_path)\n",
    "        ds.to_netcdf(cat_raw_path(fname))\n",
    "    else:\n",
    "        print(str(counter)+'. '+outfile_with_path+' already exists!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dbabaa-0911-4fbd-826f-054a6acfe3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One further refinement - STILL TO BE IMPLEMENTED\n",
    "#\n",
    "# Instead of re-loading the full drifter dataset, use the existing previous \n",
    "# file and append the new data.\n",
    "\n",
    "if 0:\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "    # crop data so that the last day is fully sampled and there are no\n",
    "    # overlaps when the data are updated; basically discard the last day if\n",
    "    # it's incomplete\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "    end_datetime = pd.to_datetime(ds.time.values[-1])\n",
    "    end_datestr = end_datetime.strftime(url_strftime)\n",
    "\n",
    "    penultimate_datetime = end_datetime - timedelta(days=1)\n",
    "    penultimate_datestr = penultimate_datetime.strftime(url_strftime)\n",
    "\n",
    "    if download_start_date == end_datestr:\n",
    "        sys.exit(\"No updated data. Last full day available is %s\" \n",
    "            % penultimate_datestr)\n",
    "\n",
    "\n",
    "    cutoff_date = pd.to_datetime(end_datestr +\" 00:00:00\",\n",
    "                                 format=timcol_strftime)\n",
    "\n",
    "    ds_crop = ds.where(ds.time<cutoff_date, drop=True)\n",
    "\n",
    "    # timestamp for filename\n",
    "    fname_timestamp = penultimate_datetime.strftime(tstamp_strftime)\n",
    "\n",
    "    # stitch together the files\n",
    "    if len(existing_files) > 0:\n",
    "        print(\"Stitch updated dataset with the previous one. \\n\")\n",
    "        # use previously opened dataset (prev_ds)\n",
    "        # put both datasets in a list\n",
    "        d = []\n",
    "        d.append(prev_ds)\n",
    "        d.append(ds_crop)\n",
    "\n",
    "        # merge list into a dataset\n",
    "        new_ds = xr.concat(d, dim='n')\n",
    "\n",
    "    else:\n",
    "        new_ds = ds_crop\n",
    "\n",
    "\n",
    "    # Filename and path of (updated) dataset\n",
    "    update_fname = f\"{fnames.fname_rawdata}{fname_timestamp}.nc\"\n",
    "    update_fpath = os.path.join(data_dir, update_fname)\n",
    "\n",
    "    # Save dataset to netcdf file\n",
    "    new_ds.to_netcdf(update_fpath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e05348d-c9b0-4e4f-90e7-88e24cf804dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../01-data/01-raw/pid300234066516050_20211117.nc already exists!\n",
      "../01-data/01-raw/pid300234068343380_20210121.nc already exists!\n",
      "../01-data/01-raw/pid300234068243550_20210822.nc already exists!\n",
      "../01-data/01-raw/pid300234066514020_20211018.nc already exists!\n",
      "../01-data/01-raw/pid300234066515050_20210428.nc already exists!\n",
      "../01-data/01-raw/pid300234068348010_20220104.nc already exists!\n",
      "../01-data/01-raw/pid300234066514030_20210525.nc already exists!\n",
      "../01-data/01-raw/pid300234066514040_20210226.nc already exists!\n",
      "../01-data/01-raw/pid300234066514050_20200213.nc already exists!\n",
      "../01-data/01-raw/pid300234066513030_20211209.nc already exists!\n",
      "../01-data/01-raw/pid300234068343430_20210404.nc already exists!\n",
      "../01-data/01-raw/pid300234066416780_20220102.nc already exists!\n",
      "../01-data/01-raw/pid300234068244620_20220104.nc already exists!\n",
      "../01-data/01-raw/pid300234066513040_20201020.nc already exists!\n",
      "../01-data/01-raw/pid300234066513050_20220101.nc already exists!\n",
      "../01-data/01-raw/pid300234068343450_20210226.nc already exists!\n",
      "../01-data/01-raw/pid300234066512030_20210214.nc already exists!\n",
      "../01-data/01-raw/pid300234066511010_20201206.nc already exists!\n",
      "../01-data/01-raw/pid300234068343460_20210324.nc already exists!\n",
      "../01-data/01-raw/pid300234066512040_20210221.nc already exists!\n",
      "../01-data/01-raw/pid300234068342440_20210207.nc already exists!\n",
      "../01-data/01-raw/pid300234066511020_20210516.nc already exists!\n",
      "../01-data/01-raw/pid300234066510000_20200312.nc already exists!\n",
      "../01-data/01-raw/pid300234068342970_20210515.nc already exists!\n",
      "../01-data/01-raw/pid300234068342460_20201008.nc already exists!\n",
      "../01-data/01-raw/pid300234066416830_20211013.nc already exists!\n",
      "../01-data/01-raw/pid300234066511040_20211211.nc already exists!\n",
      "../01-data/01-raw/pid300234066416840_20200307.nc already exists!\n",
      "../01-data/01-raw/pid300234066511050_20200313.nc already exists!\n",
      "../01-data/01-raw/pid300234066510030_20211011.nc already exists!\n",
      "../01-data/01-raw/pid300234068343000_20210126.nc already exists!\n",
      "../01-data/01-raw/pid300234068440280_20200715.nc already exists!\n",
      "../01-data/01-raw/pid300234066416860_20200907.nc already exists!\n",
      "../01-data/01-raw/pid300234066510050_20210802.nc already exists!\n",
      "../01-data/01-raw/pid300234068344040_20210319.nc already exists!\n",
      "../01-data/01-raw/pid300234068243690_20200601.nc already exists!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0b/1448f7v57h97h1dnny_s99600000gr/T/ipykernel_53682/3177293168.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Load data into an xarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     ds = load_one_drifter(pid1, base_url, username, password,\n\u001b[0m\u001b[1;32m      8\u001b[0m                                download_start_date)\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/0b/1448f7v57h97h1dnny_s99600000gr/T/ipykernel_53682/2248425939.py\u001b[0m in \u001b[0;36mload_one_drifter\u001b[0;34m(PID, base_url, username, password, download_start_date)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Request file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m#    print(resp.status_code)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Print the response code (200 is good. If you get something else, may be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/requests/models.py\u001b[0m in \u001b[0;36mcontent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    834\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m                 if (\n\u001b[1;32m    521\u001b[0m                     \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load all the TERIFIC data into raw files\n",
    "if 0:\n",
    "    for i in range(len(PID)):\n",
    "        pid1 = (PID[\"PID\"].values)[i].astype('str')\n",
    "        PID1 = (PID[\"PID\"].values)[i]\n",
    "\n",
    "        # Load data into an xarray\n",
    "        ds = load_one_drifter(pid1, base_url, username, password,\n",
    "                                   download_start_date)\n",
    "\n",
    "\n",
    "        # Get values for attributes\n",
    "        dstr = datetime.datetime.today()\n",
    "        dstr = dstr.replace(hour=0, minute=0, second=0, \n",
    "                            microsecond=0).strftime('%Y-%m-%d')\n",
    "\n",
    "        maxtime = ds.time.max().values\n",
    "        maxtimestr = pd.to_datetime(maxtime).strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "\n",
    "        project_name = 'TERIFIC'\n",
    "        operator_name = \"EFW\"\n",
    "        institution_name = 'National Oceanography Centre, UK'\n",
    "\n",
    "\n",
    "        # Create a dictionary of attributes\n",
    "        attr_dict = {\"Platform_ID\": PID1,\n",
    "                     \"End Time\": maxtimestr,\n",
    "                     \"Project\": project_name,\n",
    "                     \"Originator\": operator_name,\n",
    "                     \"Institution\": institution_name,\n",
    "                     \"Date created\": dstr,\n",
    "                    }\n",
    "\n",
    "\n",
    "        ds = ds.assign_attrs(attr_dict)\n",
    "\n",
    "        ds = ds.drop('Platform_ID')\n",
    "\n",
    "        # Save file to raw - only if it doesn't already exist\n",
    "        enddate = pd.to_datetime(maxtime).strftime('%Y%m%d')\n",
    "        fname = 'pid'+str(PID1)+'_'+enddate+'.nc'\n",
    "\n",
    "        outfile_with_path = cat_raw_path(fname)\n",
    "        if not os.path.isfile(outfile_with_path):\n",
    "            ds.to_netcdf(cat_raw_path(fname))\n",
    "        else:\n",
    "            print(outfile_with_path+' already exists!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_drifters",
   "language": "python",
   "name": "env_drifters"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
